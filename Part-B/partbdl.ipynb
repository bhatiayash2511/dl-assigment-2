{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Importing Libraries and Dependencies"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T21:02:46.526681Z","iopub.status.busy":"2024-04-06T21:02:46.526302Z","iopub.status.idle":"2024-04-06T21:02:46.534752Z","shell.execute_reply":"2024-04-06T21:02:46.533631Z","shell.execute_reply.started":"2024-04-06T21:02:46.526653Z"},"id":"c7R2Y374DBhE","trusted":true},"outputs":[],"source":["import numpy as np\n","import random\n","import torch.nn as nn\n","import torch\n","import torch.optim as optim\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, random_split\n","from torchvision import datasets, transforms\n","from torchvision.transforms import RandomHorizontalFlip, ToTensor, Compose, RandomRotation, Resize\n","import matplotlib.pyplot as plt\n","from torchvision.datasets import ImageFolder\n","from PIL import Image\n","torch.manual_seed(74)\n","random.seed(74)\n","np.random.seed(74)\n","import torch\n","import torchvision.models as models"]},{"cell_type":"markdown","metadata":{},"source":["## Check if CUDA is available, else use CPU"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-06T21:02:46.537413Z","iopub.status.busy":"2024-04-06T21:02:46.536369Z","iopub.status.idle":"2024-04-06T21:02:46.548295Z","shell.execute_reply":"2024-04-06T21:02:46.547119Z","shell.execute_reply.started":"2024-04-06T21:02:46.537384Z"},"id":"Ab5Zx0dyHNAM","outputId":"438e3367-0e02-4ee0-9b69-2f7bd4fe7ce0","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"markdown","metadata":{},"source":["## Functions for getting pre-trained desired model, freeze layers and print which layers require gradients "]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-04-06T21:02:46.571077Z","iopub.status.busy":"2024-04-06T21:02:46.570728Z","iopub.status.idle":"2024-04-06T21:02:46.579082Z","shell.execute_reply":"2024-04-06T21:02:46.578079Z","shell.execute_reply.started":"2024-04-06T21:02:46.571051Z"},"id":"yPyQcLmH5bLB","outputId":"2e2080aa-655f-4c94-a687-e4387b29c71e","trusted":true},"outputs":[],"source":["# Function to get desired pre-trained model\n","def get_desired_model(model_name):\n","    if model_name.lower() == \"googlenet\":\n","        model = models.googlenet(pretrained=True)\n","    elif model_name.lower() == \"resnet18\":\n","        model = models.resnet50(pretrained=True)\n","    else:\n","        model = models.alexnet(pretrained=True)\n","    return model\n","\n","# Function to freeze layers in the model\n","def freeze_layers(model, freeze_from_layer, freeze_to_layer):\n","    for idx, (name, param) in enumerate(model.named_children()):\n","        if idx >= freeze_from_layer and idx < freeze_to_layer:\n","            for param in param.parameters():\n","                param.requires_grad = False\n","\n","# Function to print which layers require gradients\n","def print_requires_grad(model):\n","    for name, param in model.named_parameters():\n","        print(name, param.requires_grad)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Train_model function"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T21:02:46.625047Z","iopub.status.busy":"2024-04-06T21:02:46.624257Z","iopub.status.idle":"2024-04-06T21:02:46.644794Z","shell.execute_reply":"2024-04-06T21:02:46.643670Z","shell.execute_reply.started":"2024-04-06T21:02:46.625021Z"},"id":"asSqvr8b5kNJ","trusted":true},"outputs":[],"source":["def train_model(data_aug, model, train_dir, val_dir, num_epochs, batch_size, learning_rate, optimizer_name, img_size):\n","    # Define transforms for data augmentation and normalization\n","\n","    if data_aug:\n","        transform_train = transforms.Compose([\n","            transforms.Resize((img_size, img_size)),\n","            RandomRotation(10),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","#             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","        ])\n","    else:\n","        transform_train = transforms.Compose([\n","            transforms.Resize((img_size, img_size)),\n","            transforms.ToTensor(),\n","#             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","        ])\n","\n","    transform_val = transforms.Compose([\n","        transforms.Resize((img_size, img_size)),\n","        # transforms.CenterCrop(32),\n","        transforms.ToTensor(),\n","#         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","\n","    # Load the datasets using ImageFolder\n","    train_dataset = ImageFolder(train_dir, transform=transform_train)\n","    val_dataset = ImageFolder(val_dir, transform=transform_val)\n","\n","\n","    labels = train_dataset.classes\n","    train_set, val_set = random_split(train_dataset, [8000, 1999])\n","\n","    # Create data loaders for training and validation\n","    train_loader = DataLoader(train_set, batch_size=batch_size, num_workers = 4,shuffle=True)\n","    val_loader = DataLoader(val_set, batch_size=batch_size,num_workers = 4, shuffle=True)\n","    test_loader = DataLoader(val_dataset, batch_size=batch_size,num_workers = 4, shuffle=True)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    if optimizer_name.lower() == 'sgd':\n","        # print(\"SGD\")\n","        optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9)\n","    elif optimizer_name.lower() == 'rmsprop':\n","        optimizer = optim.RMSprop(model.parameters(), lr = learning_rate, alpha = 0.99, eps = 1e-8)\n","        # print(\"RMSPROP\")\n","    elif optimizer_name.lower() == 'adagrad':\n","        optimizer = optim.Adagrad(model.parameters(), lr = learning_rate, lr_decay = 0, weight_decay = 0, initial_accumulator_value = 0, eps = 1e-10)\n","        # print(\"ADAGRAD\")\n","    else:\n","        optimizer = optim.Adam(model.parameters(), lr = learning_rate, betas = (0.9, 0.999), eps = 1e-8)\n","        # print(\"ADAM\")\n","\n","\n","    epoch = 0\n","    while epoch < num_epochs:\n","        model.train()  # Set model to training mode\n","        count = 0\n","        running_loss, train_correct_p, train_total_p = 0.0, 0, 0\n","\n","        for i, data in train_loader:\n","            # print(i)\n","            inputs = i.to(device)\n","            labels = data.to(device)\n","#             inputs, labels = i, data\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss = running_loss + loss.item()\n","            _, pred = torch.max(outputs.data, 1)\n","            train_total_p += labels.size(0)\n","            train_correct_p += (pred == labels).sum().item()\n","\n","            running_loss = running_loss / len(train_loader)\n","            train_accuracy = (train_correct_p / train_total_p) * 100\n","            if count%32 == 31:\n","                print(f'Epoch {epoch+1}, Count {count+1}, Train Loss: {running_loss:.3f}, Train Accuracy: {train_accuracy:.2f}%')\n","            count += 1\n","#         print(count)\n","\n","        # Validate the model after each epoch\n","\n","        model.eval()  # Set model to evaluation mode\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for i, data in val_loader:\n","                inputs, labels = i.to(device), data.to(device)\n","#                 inputs, labels = i, data\n","                outputs = model.forward(inputs)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","        # Print validation statistics\n","        val_loss /= len(val_loader)\n","        val_accuracy = 100 * correct / total\n","        print(f'Epoch {epoch + 1}, Validation Loss: {val_loss:.3f}, Validation Accuracy: {val_accuracy:.2f}%')\n","        print()\n","        epoch += 1\n","    print('Training finished')\n","    return model, val_accuracy\n"]},{"cell_type":"markdown","metadata":{},"source":["# Define parameters and directories"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T21:02:46.649440Z","iopub.status.busy":"2024-04-06T21:02:46.649067Z","iopub.status.idle":"2024-04-06T21:02:46.898834Z","shell.execute_reply":"2024-04-06T21:02:46.898021Z","shell.execute_reply.started":"2024-04-06T21:02:46.649409Z"},"id":"5olPDOHFG_CP","trusted":true},"outputs":[],"source":["model_name = \"googlenet\"\n","model = get_desired_model(model_name)\n","model.fc = nn.Linear(in_features =  model.fc.in_features, out_features = 10)\n","train_dir = '/kaggle/input/nature/inaturalist_12K/train'\n","val_dir = '/kaggle/input/nature/inaturalist_12K/val'"]},{"cell_type":"markdown","metadata":{},"source":["1. Technique - Freezing first k layers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["freeze_from_layer = 0         # Start freezing from the first layer\n","freeze_to_layer = 8           # Freeze layers up to the kth layer\n","# print_requires_grad(model)\n","freeze_layers(model, freeze_from_layer, freeze_to_layer)\n","# print_requires_grad(model)\n","model = model.to(device)\n","\n","num_epochs = 10\n","learning_rate = 0.001\n","batch_size = 250\n","# Instantiate the ConvNet model\n","img_size = 256\n","optimizer_name = \"ADAM\"\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"H9UP367nKhnm"},"source":["Execueting train_model function"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"execution":{"iopub.execute_input":"2024-04-06T21:02:46.901266Z","iopub.status.busy":"2024-04-06T21:02:46.900567Z","iopub.status.idle":"2024-04-06T21:11:23.935458Z","shell.execute_reply":"2024-04-06T21:11:23.934186Z","shell.execute_reply.started":"2024-04-06T21:02:46.901233Z"},"id":"ylw53YT6HCDt","outputId":"bfc808cd-7b95-42e0-cffb-c4b6e6cd42a2","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Count 32, Train Loss: 0.028, Train Accuracy: 63.05%\n","Epoch 1, Validation Loss: 0.912, Validation Accuracy: 69.68%\n","\n","Epoch 2, Count 32, Train Loss: 0.013, Train Accuracy: 85.11%\n","Epoch 2, Validation Loss: 0.876, Validation Accuracy: 70.94%\n","\n","Epoch 3, Count 32, Train Loss: 0.006, Train Accuracy: 94.47%\n","Epoch 3, Validation Loss: 0.937, Validation Accuracy: 72.29%\n","\n","Epoch 4, Count 32, Train Loss: 0.003, Train Accuracy: 96.97%\n","Epoch 4, Validation Loss: 1.020, Validation Accuracy: 72.64%\n","\n","Epoch 5, Count 32, Train Loss: 0.001, Train Accuracy: 98.15%\n","Epoch 5, Validation Loss: 1.209, Validation Accuracy: 69.23%\n","\n","Epoch 6, Count 32, Train Loss: 0.003, Train Accuracy: 97.92%\n","Epoch 6, Validation Loss: 1.133, Validation Accuracy: 71.49%\n","\n","Epoch 7, Count 32, Train Loss: 0.003, Train Accuracy: 97.00%\n","Epoch 7, Validation Loss: 1.214, Validation Accuracy: 71.04%\n","\n","Epoch 8, Count 32, Train Loss: 0.003, Train Accuracy: 97.15%\n","Epoch 8, Validation Loss: 1.340, Validation Accuracy: 69.18%\n","\n","Epoch 9, Count 32, Train Loss: 0.003, Train Accuracy: 97.16%\n","Epoch 9, Validation Loss: 1.528, Validation Accuracy: 67.93%\n","\n","Epoch 10, Count 32, Train Loss: 0.002, Train Accuracy: 97.59%\n","Epoch 10, Validation Loss: 1.343, Validation Accuracy: 69.28%\n","\n","Training finished\n"]}],"source":["# def train_model(data_aug, model, train_dir, val_dir, num_epochs, batch_size, learning_rate, optimizer_name, img_size):\n","model, va = train_model(False, model, train_dir, val_dir, num_epochs, batch_size, learning_rate, optimizer_name, img_size)"]},{"cell_type":"markdown","metadata":{},"source":["2. Technique - Freezing some middle layers parameter defined parameters that are required"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["freeze_from_layer = 9        # Start freezing from the k+1 layer\n","freeze_to_layer = 12           # Freeze layers up to the some layer\n","# print_requires_grad(model)\n","freeze_layers(model, freeze_from_layer, freeze_to_layer)\n","# print_requires_grad(model)\n","model = model.to(device)\n","\n","num_epochs = 10\n","learning_rate = 0.001\n","batch_size = 250\n","# Instantiate the ConvNet model\n","img_size = 256\n","optimizer_name = \"ADAM\"\n","\n","model, va = train_model(False, model, train_dir, val_dir, num_epochs, batch_size, learning_rate, optimizer_name, img_size)"]},{"cell_type":"markdown","metadata":{},"source":["3. Technique - Freezing last k layers parameter defined paramters that are required"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","freeze_from_layer = 13        # Start freezing from the k+1 layer\n","freeze_to_layer = 19           # Freeze layers up to the last layer\n","# print_requires_grad(model)\n","freeze_layers(model, freeze_from_layer, freeze_to_layer)\n","# print_requires_grad(model)\n","model = model.to(device)\n","\n","num_epochs = 10\n","learning_rate = 0.001\n","batch_size = 250\n","# Instantiate the ConvNet model\n","img_size = 256\n","optimizer_name = \"ADAM\"\n","\n","model, va = train_model(False, model, train_dir, val_dir, num_epochs, batch_size, learning_rate, optimizer_name, img_size)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4734881,"sourceId":8032752,"sourceType":"datasetVersion"},{"datasetId":4746095,"sourceId":8048429,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
